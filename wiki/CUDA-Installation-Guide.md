# üöÄ –ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ CUDA+cuDNN+TensorRT

**–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∏ –ø—Ä–æ—Å—Ç–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ–ª–Ω–æ–≥–æ CUDA stack –¥–ª—è LiveSwapping —á–µ—Ä–µ–∑ conda/miniconda**

> üåç **[English version](en/CUDA-Installation-Guide)** | üá∑üá∫ **–†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è**

## üìö –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–ó–∞—á–µ–º –Ω—É–∂–Ω–∞ —ç—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞](#-–∑–∞—á–µ–º-–Ω—É–∂–Ω–∞-—ç—Ç–∞-—É—Å—Ç–∞–Ω–æ–≤–∫–∞)
2. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã](#-–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞-—Å–∏—Å—Ç–µ–º—ã)
3. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ Miniconda (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)](#-—É—Å—Ç–∞–Ω–æ–≤–∫–∞-—á–µ—Ä–µ–∑-miniconda-—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
4. [–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏](#-–ø—Ä–æ–≤–µ—Ä–∫–∞-—É—Å—Ç–∞–Ω–æ–≤–∫–∏)
5. [–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º](#-—Ä–µ—à–µ–Ω–∏–µ-–ø—Ä–æ–±–ª–µ–º)
6. [–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã](#-–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ-–º–µ—Ç–æ–¥—ã)

---

## üéØ –ó–∞—á–µ–º –Ω—É–∂–Ω–∞ —ç—Ç–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∞

### –ß—Ç–æ –¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA stack:
- **3x —É—Å–∫–æ—Ä–µ–Ω–∏–µ** LiveSwapping —Å TensorRT
- **–°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞** –±–µ–∑ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –≤–µ—Ä—Å–∏–π
- **GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ** –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å** —Å PyTorch –∏ ONNX Runtime

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã stack:
- **CUDA Toolkit** - –æ—Å–Ω–æ–≤–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ GPU –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- **cuDNN** - –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –¥–ª—è CUDA
- **TensorRT** - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è inference –¥–ª—è NVIDIA GPU
- **PyTorch** - —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
- **ONNX Runtime** - —Å GPU –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏

---

## üõ†Ô∏è –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ GPU

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è NVIDIA GPU
nvidia-smi

# –î–æ–ª–∂–µ–Ω –ø–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU:
# +-----------------------------------------------------------------------------+
# | NVIDIA-SMI 535.54.03    Driver Version: 535.54.03    CUDA Version: 12.2   |
# +-------------------------------+----------------------+----------------------+
```

### –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ GPU:
- ‚úÖ **RTX 40 series** (4090, 4080, 4070, 4060)
- ‚úÖ **RTX 30 series** (3090, 3080, 3070, 3060)
- ‚úÖ **RTX 20 series** (2080, 2070, 2060)
- ‚úÖ **GTX 16 series** (1660, 1650)
- ‚úÖ **Tesla, Quadro** —Å–µ—Ä–∏–∏
- ‚ùå **GTX 10xx –∏ —Å—Ç–∞—Ä—à–µ** (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ TensorRT)

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥—Ä–∞–π–≤–µ—Ä–∞–º:

| CUDA Version | –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ |
|--------------|----------------------------|
| CUDA 12.1 | 530.30.02+ (Linux), 531.14+ (Windows) |
| CUDA 12.4 | 550.54.15+ (Linux), 551.61+ (Windows) |
| CUDA 11.8 | 520.61.05+ (Linux), 522.06+ (Windows) |

---

## üêç –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ Miniconda (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

### –ü–æ—á–µ–º—É conda –ª—É—á—à–µ –≤—Å–µ–≥–æ:
- ‚úÖ **–ò–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è** - –Ω–∏–∫–∞–∫–∏—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
- ‚úÖ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ** –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
- ‚úÖ **–ü—Ä–µ–¥–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ** –ø–∞–∫–µ—Ç—ã
- ‚úÖ **–ü—Ä–æ—Å—Ç–∞—è –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∞** –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö
- ‚úÖ **–†–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∑–¥–µ** –æ–¥–∏–Ω–∞–∫–æ–≤–æ

### –®–∞–≥ 1: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Miniconda

#### Windows:
```cmd
# –°–∫–∞—á–∞–π—Ç–µ Miniconda —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞
# https://docs.conda.io/en/latest/miniconda.html

# –ò–ª–∏ —á–µ—Ä–µ–∑ PowerShell:
Invoke-WebRequest -Uri "https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe" -OutFile "miniconda.exe"
.\miniconda.exe /S /D=C:\miniconda3

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Ä–º–∏–Ω–∞–ª –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:
C:\miniconda3\Scripts\activate.bat
```

#### Linux:
```bash
# –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
chmod +x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda3

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ PATH
echo 'export PATH="$HOME/miniconda3/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc
```

### –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å Python 3.10
conda create -n liveswapping python=3.10 -y

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
conda activate liveswapping

# –ü—Ä–æ–≤–µ—Ä–∫–∞
python --version  # –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å Python 3.10.x
which python      # –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –ø—É—Ç—å –≤ miniconda
```

### –®–∞–≥ 3: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA Toolkit —á–µ—Ä–µ–∑ conda

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA 12.1 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è PyTorch 2.1+)
conda install nvidia/label/cuda-12.1.0::cuda-toolkit -y

# –ò–ª–∏ CUDA 11.8 (–¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞—Ä—ã—Ö —Å–∏—Å—Ç–µ–º)
# conda install nvidia/label/cuda-11.8.0::cuda-toolkit -y

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
nvcc --version
```

### –®–∞–≥ 4: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ cuDNN

```bash
# cuDNN —á–µ—Ä–µ–∑ conda-forge
conda install conda-forge::cudnn -y

# –ò–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–ª—è CUDA 12.1
conda install nvidia::cudnn=8.9.7.29 -y
```

### –®–∞–≥ 5: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA

```bash
# PyTorch —Å CUDA 12.1 support
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y

# –ò–ª–∏ –¥–ª—è CUDA 11.8
# conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y
```

### –®–∞–≥ 6: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ TensorRT

```bash
# TensorRT —á–µ—Ä–µ–∑ pip (—Ç–∞–∫ –∫–∞–∫ conda –≤–µ—Ä—Å–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–µ–π)
pip install torch-tensorrt --extra-index-url https://download.pytorch.org/whl/cu121

# –ò–ª–∏ –¥–ª—è CUDA 11.8
# pip install torch-tensorrt --extra-index-url https://download.pytorch.org/whl/cu118
```

### –®–∞–≥ 7: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# ONNX Runtime —Å GPU –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
pip install onnxruntime-gpu

# CuPy –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è numpy –æ–ø–µ—Ä–∞—Ü–∏–π
conda install cupy -c conda-forge -y

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
pip install opencv-python pillow numpy scipy
```

### –®–∞–≥ 8: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ LiveSwapping

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
git clone https://github.com/NeuroDonu/LiveSwapping.git
cd LiveSwapping

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
pip install -e .

# –ò–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
pip install -r requirements/requirements_cuda.txt
```

---

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏

### –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `test_cuda_stack.py`:

```python
#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ CUDA stack –¥–ª—è LiveSwapping
"""

import sys
import subprocess

def check_component(name, check_func):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ —Å —Ü–≤–µ—Ç–Ω—ã–º –≤—ã–≤–æ–¥–æ–º."""
    try:
        result = check_func()
        if result:
            print(f"‚úÖ {name}: OK")
            if isinstance(result, str):
                print(f"   {result}")
        else:
            print(f"‚ùå {name}: FAILED")
        return bool(result)
    except Exception as e:
        print(f"‚ùå {name}: ERROR - {e}")
        return False

def check_python():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ Python."""
    version = sys.version.split()[0]
    major, minor = map(int, version.split('.')[:2])
    if major == 3 and minor >= 8:
        return f"Python {version}"
    return None

def check_conda():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ conda –æ–∫—Ä—É–∂–µ–Ω–∏—è."""
    try:
        result = subprocess.run(['conda', '--version'], 
                              capture_output=True, text=True, check=True)
        env_name = subprocess.run(['conda', 'info', '--envs'], 
                                capture_output=True, text=True, check=True)
        if '*' in env_name.stdout:
            active_env = [line for line in env_name.stdout.split('\n') 
                         if '*' in line][0].split()[0]
            return f"{result.stdout.strip()}, active env: {active_env}"
        return result.stdout.strip()
    except:
        return None

def check_cuda_toolkit():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA Toolkit."""
    try:
        result = subprocess.run(['nvcc', '--version'], 
                              capture_output=True, text=True, check=True)
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –∏–∑ –≤—ã–≤–æ–¥–∞ nvcc
        lines = result.stdout.split('\n')
        version_line = [line for line in lines if 'release' in line][0]
        version = version_line.split('release ')[1].split(',')[0]
        return f"CUDA {version}"
    except:
        return None

def check_nvidia_driver():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞ NVIDIA."""
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=driver_version', 
                               '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True, check=True)
        driver_version = result.stdout.strip()
        return f"Driver {driver_version}"
    except:
        return None

def check_pytorch():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ PyTorch —Å CUDA."""
    try:
        import torch
        cuda_available = torch.cuda.is_available()
        if cuda_available:
            cuda_version = torch.version.cuda
            device_count = torch.cuda.device_count()
            current_device = torch.cuda.current_device()
            device_name = torch.cuda.get_device_name(current_device)
            return f"PyTorch {torch.__version__}, CUDA {cuda_version}, {device_count} GPU(s), Current: {device_name}"
        else:
            return f"PyTorch {torch.__version__} (CUDA NOT AVAILABLE)"
    except ImportError:
        return None

def check_tensorrt():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ TensorRT."""
    try:
        import torch_tensorrt
        return f"TensorRT {torch_tensorrt.__version__}"
    except ImportError:
        return None

def check_onnxruntime():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX Runtime."""
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        gpu_providers = [p for p in providers if 'CUDA' in p or 'DirectML' in p or 'OpenVINO' in p]
        return f"ONNX Runtime {ort.__version__}, GPU providers: {gpu_providers}"
    except ImportError:
        return None

def check_cupy():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ CuPy."""
    try:
        import cupy as cp
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
        a = cp.array([1, 2, 3])
        b = cp.array([4, 5, 6])
        c = a + b
        return f"CuPy {cp.__version__}"
    except ImportError:
        return None
    except Exception as e:
        return f"CuPy installed but error: {e}"

def check_liveswapping():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ LiveSwapping."""
    try:
        from liveswapping.utils.gpu_utils import print_gpu_info, get_optimal_provider
        provider = get_optimal_provider()
        return f"LiveSwapping OK, optimal provider: {provider}"
    except ImportError:
        return None

def performance_test():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
    try:
        import torch
        import time
        
        if not torch.cuda.is_available():
            return "CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
        
        device = torch.device('cuda')
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        a = torch.randn(1000, 1000, device=device)
        b = torch.randn(1000, 1000, device=device)
        
        # –ü—Ä–æ–≥—Ä–µ–≤
        for _ in range(10):
            c = torch.mm(a, b)
        torch.cuda.synchronize()
        
        # –¢–µ—Å—Ç
        start_time = time.time()
        for _ in range(100):
            c = torch.mm(a, b)
        torch.cuda.synchronize()
        end_time = time.time()
        
        avg_time = (end_time - start_time) / 100
        ops_per_sec = 1.0 / avg_time
        
        return f"Matrix multiplication: {avg_time:.4f}s per op, {ops_per_sec:.1f} ops/sec"
        
    except Exception as e:
        return f"Performance test failed: {e}"

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏."""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê CUDA STACK –î–õ–Ø LIVESWAPPING")
    print("=" * 60)
    
    checks = [
        ("Python", check_python),
        ("Conda", check_conda),
        ("NVIDIA Driver", check_nvidia_driver),
        ("CUDA Toolkit", check_cuda_toolkit),
        ("PyTorch", check_pytorch),
        ("TensorRT", check_tensorrt),
        ("ONNX Runtime", check_onnxruntime),
        ("CuPy", check_cupy),
        ("LiveSwapping", check_liveswapping),
    ]
    
    results = []
    for name, check_func in checks:
        result = check_component(name, check_func)
        results.append(result)
    
    print("\nüöÄ –¢–ï–°–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("-" * 30)
    check_component("GPU Performance", performance_test)
    
    print(f"\nüìä –û–ë–©–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢")
    print("-" * 20)
    success_count = sum(results)
    total_count = len(results)
    
    if success_count == total_count:
        print("üéâ –í–°–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ –†–ê–ë–û–¢–ê–Æ–¢ –û–¢–õ–ò–ß–ù–û!")
        print("   LiveSwapping –≥–æ—Ç–æ–≤ –∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    elif success_count >= 6:
        print("‚úÖ –°–ò–°–¢–ï–ú–ê –ì–û–¢–û–í–ê –ö –†–ê–ë–û–¢–ï")
        print("   –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –Ω–æ –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç–∞–µ—Ç")
    else:
        print("‚ö†Ô∏è  –¢–†–ï–ë–£–ï–¢–°–Ø –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–µ—É–¥–∞—á–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É")
    
    print(f"\n–°—Ç–∞—Ç—É—Å: {success_count}/{total_count} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞—é—Ç")

if __name__ == "__main__":
    main()
```

–ó–∞–ø—É—Å—Ç–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É:

```bash
python test_cuda_stack.py
```

### –û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥ (—É—Å–ø–µ—à–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞):

```
üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê CUDA STACK –î–õ–Ø LIVESWAPPING
============================================================
‚úÖ Python: OK
   Python 3.10.12
‚úÖ Conda: OK
   conda 23.7.4, active env: liveswapping
‚úÖ NVIDIA Driver: OK
   Driver 535.54.03
‚úÖ CUDA Toolkit: OK
   CUDA 12.1
‚úÖ PyTorch: OK
   PyTorch 2.1.0, CUDA 12.1, 1 GPU(s), Current: NVIDIA GeForce RTX 4090
‚úÖ TensorRT: OK
   TensorRT 2.1.0
‚úÖ ONNX Runtime: OK
   ONNX Runtime 1.16.1, GPU providers: ['CUDAExecutionProvider']
‚úÖ CuPy: OK
   CuPy 12.2.0
‚úÖ LiveSwapping: OK
   optimal provider: cuda

üöÄ –¢–ï–°–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò
------------------------------
‚úÖ GPU Performance: OK
   Matrix multiplication: 0.0001s per op, 8542.3 ops/sec

üìä –û–ë–©–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢
--------------------
üéâ –í–°–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ –†–ê–ë–û–¢–ê–Æ–¢ –û–¢–õ–ò–ß–ù–û!
   LiveSwapping –≥–æ—Ç–æ–≤ –∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

–°—Ç–∞—Ç—É—Å: 9/9 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞—é—Ç
```

---

## üîß –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –ü—Ä–æ–±–ª–µ–º–∞ 1: "CUDA driver version is insufficient"

**–°–∏–º–ø—Ç–æ–º—ã:**
```
RuntimeError: CUDA driver version is insufficient for CUDA runtime version
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–µ—Ä—Å–∏—é –¥—Ä–∞–π–≤–µ—Ä–∞
nvidia-smi

# –û–±–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä NVIDIA:
# Windows: https://www.nvidia.com/drivers/
# Ubuntu: sudo apt update && sudo apt install nvidia-driver-535

# –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É
sudo reboot
```

### –ü—Ä–æ–±–ª–µ–º–∞ 2: "torch-tensorrt compilation failed"

**–°–∏–º–ø—Ç–æ–º—ã:**
```
WARNING: torch-tensorrt compilation failed, falling back to PyTorch
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ torch-tensorrt
pip uninstall torch-tensorrt
pip install torch-tensorrt --extra-index-url https://download.pytorch.org/whl/cu121

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}')"
```

### –ü—Ä–æ–±–ª–µ–º–∞ 3: –ö–æ–Ω—Ñ–ª–∏–∫—Ç –≤–µ—Ä—Å–∏–π CUDA

**–°–∏–º–ø—Ç–æ–º—ã:**
```
RuntimeError: CUDA version mismatch
```

**–†–µ—à–µ–Ω–∏–µ - –ø–æ–ª–Ω–∞—è –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∞:**
```bash
# –î–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
conda deactivate

# –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
conda env remove -n liveswapping

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –Ω—É–ª—è
conda create -n liveswapping python=3.10 -y
conda activate liveswapping

# –ß–∏—Å—Ç–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ–≥–æ stack
conda install nvidia/label/cuda-12.1.0::cuda-toolkit -y
conda install conda-forge::cudnn -y
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y
pip install torch-tensorrt --extra-index-url https://download.pytorch.org/whl/cu121
```

### –ü—Ä–æ–±–ª–µ–º–∞ 4: "No module named 'cupy'"

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ CuPy –¥–ª—è CUDA 12.1
conda install cupy -c conda-forge

# –ò–ª–∏ —á–µ—Ä–µ–∑ pip —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π CUDA
pip install cupy-cuda12x
```

### –ü—Ä–æ–±–ª–µ–º–∞ 5: –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ GPU

**–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:**
```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"Current device: {torch.cuda.current_device()}")
print(f"Device name: {torch.cuda.get_device_name()}")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç GPU
from liveswapping.ai_models.models import get_optimal_provider
print(f"Optimal provider: {get_optimal_provider()}")
```

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã
export CUDA_VISIBLE_DEVICES=0
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É GPU –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
nvidia-smi -l 1
```

---

## üîÑ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã

### –ú–µ—Ç–æ–¥ 2: Docker (–¥–ª—è –æ–ø—ã—Ç–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π)

```dockerfile
# Dockerfile –¥–ª—è LiveSwapping —Å CUDA
FROM nvidia/cuda:12.1-devel-ubuntu22.04

RUN apt-get update && apt-get install -y \
    python3 python3-pip git \
    && rm -rf /var/lib/apt/lists/*

RUN pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
RUN pip3 install torch-tensorrt onnxruntime-gpu cupy-cuda12x

WORKDIR /app
COPY . .
RUN pip3 install -e .

CMD ["python3", "run.py"]
```

### –ú–µ—Ç–æ–¥ 3: –°–∏—Å—Ç–µ–º–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

<details>
<summary>‚ö†Ô∏è –¢–æ–ª—å–∫–æ –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–º–æ–∂–µ—Ç —Å–ª–æ–º–∞—Ç—å —Å–∏—Å—Ç–µ–º—É)</summary>

```bash
# –í–ù–ò–ú–ê–ù–ò–ï: –ú–æ–∂–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏!

# Ubuntu - —É—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA Toolkit
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-ubuntu2204-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2204-12-1-local_12.1.0-530.30.02-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2204-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ PATH –∏ LD_LIBRARY_PATH
echo 'export PATH=/usr/local/cuda-12.1/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

</details>

---

## üéØ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ LiveSwapping

–ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–±–æ—Ç—É LiveSwapping:

```bash
# –ó–∞–ø—É—Å–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
python test_cuda_stack.py

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
python -c "
from liveswapping.ai_models.models import load_model, get_optimal_provider
print(f'Optimal provider: {get_optimal_provider()}')
model = load_model('reswapper128', use_tensorrt=True)
print('‚úÖ Model loaded successfully with TensorRT!')
"

# –¢–µ—Å—Ç GUI
python run.py
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **[NVIDIA CUDA Toolkit Documentation](https://docs.nvidia.com/cuda/)**
- **[PyTorch Installation Guide](https://pytorch.org/get-started/locally/)**
- **[TensorRT Developer Guide](https://docs.nvidia.com/deeplearning/tensorrt/)**
- **[Conda User Guide](https://docs.conda.io/en/latest/)**

---

## üÜò –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–º–æ—â–∏

–ï—Å–ª–∏ —É –≤–∞—Å –æ—Å—Ç–∞–ª–∏—Å—å –ø—Ä–æ–±–ª–µ–º—ã:

1. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É:** `python test_cuda_stack.py`
2. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏:** —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –≤—ã–≤–æ–¥ –∫–æ–º–∞–Ω–¥
3. **–°–æ–∑–¥–∞–π—Ç–µ issue:** [GitHub Issues](https://github.com/NeuroDonu/LiveSwapping/issues)
4. **–ü—Ä–∏–ª–æ–∂–∏—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:**
   - –í—ã–≤–æ–¥ `nvidia-smi`
   - –í—ã–≤–æ–¥ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞
   - –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∏ –≤–µ—Ä—Å–∏—è
   - –ú–æ–¥–µ–ª—å GPU

---

> **üí° –°–æ–≤–µ—Ç:** –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ conda –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏! –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª–µ–≥–∫–æ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã.

---

*[‚¨ÖÔ∏è Installation](Installation) | [üè† –ì–ª–∞–≤–Ω–∞—è](Home) | [üåç English version](en/CUDA-Installation-Guide)*