# -*- coding: utf-8 -*-
"""–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ —Å –±–∞—Ç—á–∏–Ω–≥–æ–º –∏ –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å—é.

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç BatchProcessor –¥–ª—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
—á–µ—Ä–µ–∑:
- –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏
- –ë–∞—Ç—á–∏–Ω–≥ AI-–º–æ–¥–µ–ª–µ–π (–Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–∏—Ü –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤
- –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–µ–π
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

from __future__ import annotations

import argparse
import os
import cv2
import numpy as np
import torch
import time
from typing import Sequence, Optional, Dict, Any, List, Tuple
from dataclasses import dataclass
from tqdm import tqdm
import shutil
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import queue

# –û—Ç–∫–ª—é—á–∞–µ–º verbose –ª–æ–≥–∏ ONNX Runtime
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['ONNX_LOG_LEVEL'] = '3'
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="onnxruntime")
import onnxruntime as ort
ort.set_default_logger_severity(3)

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ LiveSwapping
from liveswapping.core import image_utils as Image
from liveswapping.utils.batch_processor import (
    BatchProcessor, 
    AsyncFrameReader, 
    get_optimal_batch_config,
    get_gpu_memory_info
)
from liveswapping.core.video import (
    parse_arguments, 
    faceAnalysis, 
    load_model, 
    create_source_latent, 
    apply_color_transfer
)
from insightface.app import FaceAnalysis
from moviepy import AudioFileClip, VideoFileClip
from moviepy.video.io.ImageSequenceClip import ImageSequenceClip
from gfpgan import GFPGANer


@dataclass
class ProcessingStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ."""
    total_frames: int
    processed_frames: int
    dropped_frames: int
    total_time: float
    avg_fps: float
    batch_size_used: int
    gpu_memory_peak: float


class OptimizedVideoProcessor:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤–∏–¥–µ–æ —Å –±–∞—Ç—á–∏–Ω–≥–æ–º."""
    
    def __init__(self, args):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞."""
        self.args = args
        self.model = None
        self.source_latent = None
        self.batch_processor = None
        self.face_analysis = faceAnalysis
        
        # torch.compile() –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.enable_torch_compile = getattr(args, 'enable_torch_compile', True)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = ProcessingStats(
            total_frames=0,
            processed_frames=0,
            dropped_frames=0,
            total_time=0.0,
            avg_fps=0.0,
            batch_size_used=0,
            gpu_memory_peak=0.0
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self.optimization_config = None
        
    def _optimize_model_with_compile(self, model) -> Any:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Å torch.compile() –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ."""
        if not self.enable_torch_compile:
            return model
            
        try:
            if hasattr(torch, 'compile'):
                torch_version = torch.__version__
                major, minor = map(int, torch_version.split('.')[:2])
                if major >= 2:
                    # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ä–µ–∂–∏–º—ã –∫–æ–º–ø–∏–ª—è—Ü–∏–∏, –Ω–∞—á–∏–Ω–∞—è —Å —Å–∞–º—ã—Ö –ø—Ä–æ—Å—Ç—ã—Ö
                    compile_attempts = [
                        # –ë–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º –±–µ–∑ Triton (–º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ Triton)
                        ("default", {}),
                        # –†–µ–∂–∏–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏
                        ("reduce-overhead", {"mode": "reduce-overhead"}),
                        # –ü–æ–ø—Ä–æ–±—É–µ–º –±–µ–∑ fullgraph
                        ("reduce-overhead-simple", {"mode": "reduce-overhead", "fullgraph": False}),
                    ]
                    
                    for mode_name, compile_kwargs in compile_attempts:
                        try:
                            #print(f"[OPTIMIZE] –ü–æ–ø—ã—Ç–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ video –º–æ–¥–µ–ª–∏ —Å —Ä–µ–∂–∏–º–æ–º '{mode_name}'...")
                            compiled_model = torch.compile(model, **compile_kwargs)
                            
                            # –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
                            with torch.no_grad():
                                dummy_input = torch.randn(1, 3, 128, 128).cuda()
                                dummy_latent = torch.randn(1, 512).cuda()
                                _ = compiled_model(dummy_input, dummy_latent)
                            
                            #print(f"[OPTIMIZE] ‚úÖ Video –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞ —Å —Ä–µ–∂–∏–º–æ–º '{mode_name}'!")
                            return compiled_model
                            
                        except Exception as e:
                            print(f"[WARNING] –†–µ–∂–∏–º '{mode_name}' –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {str(e)[:100]}...")
                            continue
                    
                    # –ï—Å–ª–∏ –≤—Å–µ —Ä–µ–∂–∏–º—ã –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—É—é –º–æ–¥–µ–ª—å
                    #print("[INFO] –í—Å–µ —Ä–µ–∂–∏–º—ã –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å")
                    #print("[INFO] –î–ª—è –ø–æ–ª–Ω–æ–≥–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Triton: pip install triton")
        except Exception as e:
            print(f"[WARNING] –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å video –º–æ–¥–µ–ª—å: {e}")
        
        return model
        
    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞."""
        #print("[OptimizedVideoProcessor] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...")
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
        self.model = load_model(self.args.modelPath, provider_type=self.args.model_provider)
        
        # –ü—Ä–∏–º–µ–Ω–∏—Ç—å torch.compile() –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
        if self.enable_torch_compile:
            self.model = self._optimize_model_with_compile(self.model)
        
        # –°–æ–∑–¥–∞—Ç—å –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ª–∏—Ü–∞
        source_img = cv2.imread(self.args.source)
        if source_img is None:
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {self.args.source}")
            
        self.source_latent = create_source_latent(
            source_img, 
            self.args.face_attribute_direction, 
            self.args.face_attribute_steps
        )
        
        if self.source_latent is None:
            raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ª–∏—Ü–∞")
            
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        cap = cv2.VideoCapture(self.args.target_video)
        if not cap.isOpened():
            raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ: {self.args.target_video}")
            
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.stats.total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()
        
        self.optimization_config = get_optimal_batch_config((width, height))
        
        # –°–æ–∑–¥–∞—Ç—å –±–∞—Ç—á-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        self.batch_processor = BatchProcessor(
            face_analysis=self.face_analysis,
            model=self.model,
            source_latent=self.source_latent,
            max_batch_size=self.optimization_config["batch_size"],
            num_workers=self.optimization_config["max_workers"],
            queue_size=self.optimization_config["queue_size"],
            enable_torch_compile=False  # –ú–æ–¥–µ–ª—å —É–∂–µ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞ –≤—ã—à–µ
        )
        
        self.stats.batch_size_used = self.optimization_config["batch_size"]
        
        compile_status = "‚úÖ –í–∫–ª—é—á–µ–Ω" if self.enable_torch_compile else "‚ùå –í—ã–∫–ª—é—á–µ–Ω"
        #print(f"[OptimizedVideoProcessor] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
        #print(f"  - –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –≤–∏–¥–µ–æ: {width}x{height}")
        #print(f"  - –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤: {self.stats.total_frames}")
        #print(f"  - –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.optimization_config['batch_size']}")
        #print(f"  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤: {self.optimization_config['max_workers']}")
        #print(f"  - torch.compile(): {compile_status}")
        
        gpu_info = get_gpu_memory_info()
        if gpu_info["total"] > 0:
            pass
            #print(f"  - GPU –ø–∞–º—è—Ç—å: {gpu_info['total']:.1f}GB (–¥–æ—Å—Ç—É–ø–Ω–æ: {gpu_info['free']:.1f}GB)")
        
    def process_video(self) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏."""
        start_time = time.time()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        temp_dir = Path("temp_frames")
        temp_dir.mkdir(exist_ok=True)
        
        output_frames_dir = temp_dir / "output_frames"
        output_frames_dir.mkdir(exist_ok=True)
        
        try:
            # –ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
            if self.batch_processor is not None:
                self.batch_processor.start()
            
            # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤
            buffer_size = self.optimization_config["buffer_size"] if self.optimization_config else 30
            frame_reader = AsyncFrameReader(
                self.args.target_video, 
                buffer_size=buffer_size
            )
            frame_reader.start()
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –ø–æ—Ç–æ–∫–∏ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤
            sender_thread = threading.Thread(
                target=self._frame_sender_worker, 
                args=(frame_reader,), 
                daemon=True
            )
            receiver_thread = threading.Thread(
                target=self._frame_receiver_worker, 
                args=(output_frames_dir,), 
                daemon=True
            )
            
            sender_thread.start()
            receiver_thread.start()
            
            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            self._monitor_progress(frame_reader)
            
            # –î–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–æ–≤
            sender_thread.join(timeout=10.0)
            receiver_thread.join(timeout=10.0)
            
            # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É
            frame_reader.stop()
            if self.batch_processor is not None:
                self.batch_processor.stop()
            
            self.stats.total_time = time.time() - start_time
            self.stats.avg_fps = self.stats.processed_frames / self.stats.total_time
            
            # –°–æ–±—Ä–∞—Ç—å –≤–∏–¥–µ–æ –∏–∑ –∫–∞–¥—Ä–æ–≤
            output_path = self._assemble_video(output_frames_dir)
            
            return output_path
            
        finally:
            # –û—á–∏—Å—Ç–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            if temp_dir.exists():
                shutil.rmtree(temp_dir)
    
    def _frame_sender_worker(self, frame_reader: AsyncFrameReader):
        """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫–∞–¥—Ä–æ–≤ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É."""
        frames_sent = 0
        
        while True:
            frame_data = frame_reader.get_frame()
            if frame_data is None:
                break
                
            frame_id, frame, timestamp = frame_data
            
            # –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—é
            if self.args.source:
                try:
                    frame = apply_color_transfer(self.args.source, frame)
                except Exception as e:
                    print(f"[WARNING] –û—à–∏–±–∫–∞ —Ü–≤–µ—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è –∫–∞–¥—Ä–∞ {frame_id}: {e}")
            
            # –û—Ç–ø—Ä–∞–≤–∏—Ç—å –∫–∞–¥—Ä –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
            success = self.batch_processor.process_frame(frame, frame_id)
            if success:
                frames_sent += 1
            else:
                self.stats.dropped_frames += 1
                print(f"[WARNING] –ö–∞–¥—Ä {frame_id} –æ—Ç–±—Ä–æ—à–µ–Ω (–æ—á–µ—Ä–µ–¥—å –∑–∞–ø–æ–ª–Ω–µ–Ω–∞)")
        
        #print(f"[Sender] –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ {frames_sent} –∫–∞–¥—Ä–æ–≤, –æ—Ç–±—Ä–æ—à–µ–Ω–æ {self.stats.dropped_frames}")
        
    def _frame_receiver_worker(self, output_dir: Path):
        """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤."""
        processed_frames = {}
        next_frame_to_save = 0
        
        while True:
            result = self.batch_processor.get_result()
            if result is None:
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –≤—Å–µ –ª–∏ –∫–∞–¥—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
                if self.stats.processed_frames >= self.stats.total_frames:
                    break
                time.sleep(0.01)
                continue
                
            frame_id, processed_frame = result
            processed_frames[frame_id] = processed_frame
            
            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–¥—Ä—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
            while next_frame_to_save in processed_frames:
                frame = processed_frames.pop(next_frame_to_save)
                frame_path = output_dir / f"frame_{next_frame_to_save:06d}.png"
                cv2.imwrite(str(frame_path), frame)
                
                self.stats.processed_frames += 1
                next_frame_to_save += 1
                
                # –û–±–Ω–æ–≤–∏—Ç—å –ø–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏
                gpu_info = get_gpu_memory_info()
                if gpu_info["used"] > self.stats.gpu_memory_peak:
                    self.stats.gpu_memory_peak = gpu_info["used"]
        
        #print(f"[Receiver] –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {self.stats.processed_frames} –∫–∞–¥—Ä–æ–≤")
        
    def _monitor_progress(self, frame_reader: AsyncFrameReader):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        with tqdm(total=self.stats.total_frames, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ", unit="–∫–∞–¥—Ä–æ–≤") as pbar:
            last_processed = 0
            
            while self.stats.processed_frames < self.stats.total_frames:
                # –û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                new_processed = self.stats.processed_frames - last_processed
                if new_processed > 0:
                    pbar.update(new_processed)
                    last_processed = self.stats.processed_frames
                
                # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                if int(time.time()) % 5 == 0:
                    self._print_performance_stats()
                
                time.sleep(0.1)
            
            pbar.update(self.stats.total_frames - last_processed)
    
    def _print_performance_stats(self):
        """–í—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        if self.stats.processed_frames > 0:
            current_fps = self.stats.processed_frames / max(1, time.time() - self.stats.total_time) if self.stats.total_time > 0 else 0
            
            batch_stats = self.batch_processor.get_performance_stats()
            
            #print(f"\n[–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞] –ö–∞–¥—Ä–æ–≤: {self.stats.processed_frames}/{self.stats.total_frames}")
            #print(f"  - –¢–µ–∫—É—â–∞—è FPS: {current_fps:.1f}")
            #print(f"  - –û—Ç–±—Ä–æ—à–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: {self.stats.dropped_frames}")
            
            if batch_stats:
                pass
                #print(f"  - –°—Ä–µ–¥–Ω—è—è FPS –±–∞—Ç—á–µ–π: {batch_stats.get('avg_fps', 0):.1f}")
                #print(f"  - –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_stats.get('optimal_batch_size', 'N/A')}")
            
            gpu_info = get_gpu_memory_info()
            if gpu_info["total"] > 0:
                pass
                #print(f"  - GPU –ø–∞–º—è—Ç—å: {gpu_info['used']:.1f}/{gpu_info['total']:.1f}GB ({gpu_info['utilization']*100:.1f}%)")
    
    def _assemble_video(self, frames_dir: Path) -> str:
        """–°–æ–±—Ä–∞—Ç—å –≤–∏–¥–µ–æ –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤."""
        #print("[OptimizedVideoProcessor] –°–±–æ—Ä–∫–∞ –≤–∏–¥–µ–æ...")
        
        # –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞–¥—Ä–æ–≤
        frame_files = sorted(frames_dir.glob("frame_*.png"))
        if not frame_files:
            raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤")
        
        # –ü–æ–ª—É—á–∏—Ç—å FPS –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        cap = cv2.VideoCapture(self.args.target_video)
        fps = cap.get(cv2.CAP_PROP_FPS)
        cap.release()
        
        # –°–æ–∑–¥–∞—Ç—å –≤–∏–¥–µ–æ –∏–∑ –∫–∞–¥—Ä–æ–≤
        clip = ImageSequenceClip([str(f) for f in frame_files], fps=fps)
        
        # –î–æ–±–∞–≤–∏—Ç—å –∞—É–¥–∏–æ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –≤–∏–¥–µ–æ
        try:
            original_video = VideoFileClip(self.args.target_video)
            if original_video.audio is not None:
                clip = clip.set_audio(original_video.audio)
            original_video.close()
        except Exception as e:
            print(f"[WARNING] –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –∞—É–¥–∏–æ: {e}")
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤—ã—Ö–æ–¥–Ω–æ–π –ø—É—Ç—å
        output_path = Path(self.args.output_path)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∏–¥–µ–æ
        clip.write_videofile(
            str(output_path),
            codec='libx264',
            audio_codec='aac',
            temp_audiofile='temp-audio.m4a',
            remove_temp=True
        )
        clip.close()
        
        return str(output_path)
    
    def get_performance_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        if self.stats.total_time == 0:
            return {}
            
        speedup = self.stats.avg_fps / 25.0  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –±–∞–∑–æ–≤—É—é FPS = 25
        
        return {
            "processing_stats": {
                "total_frames": self.stats.total_frames,
                "processed_frames": self.stats.processed_frames,
                "dropped_frames": self.stats.dropped_frames,
                "success_rate": self.stats.processed_frames / self.stats.total_frames * 100,
            },
            "performance": {
                "total_time": self.stats.total_time,
                "avg_fps": self.stats.avg_fps,
                "estimated_speedup": f"{speedup:.1f}x",
                "batch_size_used": self.stats.batch_size_used,
            },
            "hardware": {
                "gpu_memory_peak": f"{self.stats.gpu_memory_peak:.1f}GB",
                "gpu_memory_total": f"{get_gpu_memory_info()['total']:.1f}GB",
            },
            "optimization_config": self.optimization_config
        }


def main_optimized(parsed_args=None):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ."""
    args = parsed_args or parse_arguments()
    
    processor = OptimizedVideoProcessor(args)
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        processor.initialize()
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞
        output_path = processor.process_video()
        
        # –û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        report = processor.get_performance_report()
        
        #print(f"\n{'='*50}")
        #print(f"‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        #print(f"{'='*50}")
        #print(f"üìÅ –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_path}")
        #print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
        
        if report:
            stats = report["processing_stats"]
            perf = report["performance"]
            hw = report["hardware"]
            
            #print(f"  üé¨ –ö–∞–¥—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed_frames']}/{stats['total_frames']} ({stats['success_rate']:.1f}%)")
            #print(f"  ‚ö° –°—Ä–µ–¥–Ω—è—è FPS: {perf['avg_fps']:.1f}")
            #print(f"  üöÄ –†–∞—Å—á–µ—Ç–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {perf['estimated_speedup']}")
            #print(f"  üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–µ–π: {perf['batch_size_used']}")
            #print(f"  ‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {perf['total_time']:.1f} —Å–µ–∫")
            #print(f"  üéÆ –ü–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU: {hw['gpu_memory_peak']}")
            
            if stats['dropped_frames'] > 0:
                print(f"  ‚ö†Ô∏è  –û—Ç–±—Ä–æ—à–µ–Ω–æ –∫–∞–¥—Ä–æ–≤: {stats['dropped_frames']}")
        
        return output_path
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
        raise


def cli_optimized(argv: Optional[Sequence[str]] = None):
    """CLI —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    return main_optimized(parse_arguments(argv))


if __name__ == "__main__":
    cli_optimized() 